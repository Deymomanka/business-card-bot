import pytesseract
from dotenv import load_dotenv
from PIL import Image
import os
import re
# from openai import OpenAI
import csv
import gspread
from google.oauth2.service_account import Credentials
import datetime

# Macã‚„Linuxã§ã¯ã“ã®è¨­å®šã¯ä¸è¦ï¼ˆWindowsã®ã¿ãƒ‘ã‚¹ãŒå¿…è¦ãªå ´åˆã‚ã‚Šï¼‰
# pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# .envã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
# load_dotenv("../.env")
# client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# api_key = os.getenv("OPENAI_API_KEY")
# print(api_key)


def extract_text_from_image(image_path):

    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
    image = Image.open(image_path)
    image.thumbnail((1024, 1024))
    text = pytesseract.image_to_string(image, lang='jpn')
    return text

# def parse_business_card(raw_text):
#     system_prompt = """
# ã‚ãªãŸã¯OCRã§èª­ã¿å–ã£ãŸååˆºæƒ…å ±ã‚’æ­£ã—ãé …ç›®ã”ã¨ã«åˆ†ã‘ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
# ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€æ¬¡ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

# {
#   "name": "",
#   "company": "",
#   "position": "",
#   "address": "",
#   "postal_code": "",
#   "tel": "",
#   "mobile": "",
#   "email": ""
# }

# ä¸æ˜ãªé …ç›®ã¯ç©ºæ¬„ "" ã«ã—ã¦ãã ã•ã„ã€‚å€¤ã®å¾Œã«èª¬æ˜ã‚„è¨˜å·ã¯ä¸è¦ã§ã™ã€‚
# """

#     response = client.chat.completions.create(
#         model="gpt-3.5-turbo",
#         messages=[
#             {"role": "system", "content": system_prompt},
#             {"role": "user", "content": raw_text}
#     ],
#     #temperature=0.2
# )

#     return response.choices[0].message.content


def extract_info_by_regex(text):
    # result = {
    #     "name": "",
    #     "company": "",
    #     "position": "",
    #     "address": "",
    #     "postal_code": "",
    #     "tel": "",
    #     "mobile": "",
    #     "email": ""
    # }

    result = {
    "date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "tel": "",
    "mobile": "",
    "email": ""
}

    # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
    email_match = re.search(r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+", text)
    if email_match:
        result["email"] = email_match.group()

    # æºå¸¯ã‚’å…ˆã«æ¢ã™
    mobile_match = re.search(r"(æºå¸¯|Mobile|Mob)[:ï¼š]?\s?(\d{2,4}-\d{2,4}-\d{3,4}|\d{10,11})", text)
    if mobile_match:
        result["mobile"] = mobile_match.group(2)
        #text = text.replace(mobile_match.group(), "")
    
    # é›»è©±ç•ªå·
    tel_match = re.search(r"(TEL|Tel|tel|é›»è©±)?[:ï¼š]?\s?(\d{2,4}-\d{2,4}-\d{3,4}|\d{10,11})", text)
    if tel_match:
        result["tel"] = tel_match.group(2)

    # # éƒµä¾¿ç•ªå·
    # postal_match = re.search(r"ã€’\d{3}-\d{4}", text)
    # if postal_match:
    #     result["postal_code"] = postal_match.group()

    # # ä½æ‰€ï¼ˆéƒ½é“åºœçœŒã‚’å«ã‚€è¡Œã‚’å¯¾è±¡ã«ï¼‰
    # address_match = re.search(r"(æ±äº¬éƒ½|åŒ—æµ·é“|å¤§é˜ªåºœ|äº¬éƒ½åºœ|.{2,3}çœŒ).+", text)
    # if address_match:
    #     result["address"] = address_match.group()

    # # ä¼šç¤¾åï¼ˆå¤§æ–‡å­—ã‚„ã‚«ã‚¿ã‚«ãƒŠå«ã‚€è¡Œã‚’æ¨å®šï¼‰
    # company_lines = [line for line in text.splitlines() if re.search(r"[A-Z]{2,}|æ ªå¼ä¼šç¤¾|æœ‰é™ä¼šç¤¾", line)]
    # if company_lines:
    #     result["company"] = company_lines[0].strip()

    return result


def is_duplicate_entry(worksheet, data):
    existing_records = worksheet.get_all_records()
    for record in existing_records:
         if (record.get("email") and record["email"] == data.get("email")) or \
           (record.get("tel") and record["tel"] == data.get("tel")):
            return True
    return False


def save_to_gsheets(data: dict, spreadsheet_name: str, worksheet_name: str):

    scopes = ["https://www.googleapis.com/auth/spreadsheets",
              "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_file(
        "key/meishi-project-gspread.json", scopes=scopes
    )
    client = gspread.authorize(creds)

    sheet = client.open(spreadsheet_name)
    worksheet = sheet.worksheet(worksheet_name)

    if not is_duplicate_entry(worksheet, data):

        #  å¿…è¦ã«å¿œã˜ã¦ã€Spreadsheetã«åˆ—åã‚’ç”¨æ„ã™ã‚‹ï¼ˆä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ï¼‰
        # fields = ["name", "company", "position", "address", "postal_code", "tel", "mobile", "email"]
        # worksheet.append_row([data.get(field, "") for field in fields])
        worksheet.append_row(list(data.values()))
        print("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    else:
        print("âš ï¸ ã™ã§ã«ç™»éŒ²æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã§ã™ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")


def process_all_images(folder_path):
    for filename in os.listdir(folder_path):
        if filename.lower().endswith((".png", ".jpg", ".jpeg")):
            full_path = os.path.join(folder_path, filename)
            print(f"\nğŸ“· å‡¦ç†ä¸­ï¼š{filename}")
            raw_text = extract_text_from_image(full_path)
            #print(raw_text)
            #structured = parse_business_card(raw_text)
            structured = extract_info_by_regex(raw_text)
            print("ğŸ“¦ æ§‹é€ åŒ–çµæœï¼š")
            print(structured)
            save_to_gsheets(structured, spreadsheet_name="ååˆºç™»éŒ²ä¸€è¦§", worksheet_name="ã‚·ãƒ¼ãƒˆ1")


if __name__ == "__main__":
    process_all_images("images/")

